import os
import re
import requests
import pymupdf4llm
from openai import OpenAI
from habanero import Crossref
from bs4 import BeautifulSoup
import time
import hashlib

# --- æ ¸å¿ƒé…ç½®åŒº ---
API_KEY = os.environ.get("LLM_API_KEY")
BASE_URL = "https://api.siliconflow.cn/v1"

# ğŸŸ¢ ä¿®æ”¹ç‚¹ï¼šä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ï¼Œè¯»ä¸åˆ°æ‰ç”¨é»˜è®¤å€¼
# è¿™æ ·ä»£ç é‡Œå°±ä¸æ˜¾ç¤ºå…·ä½“çš„æ¨¡å‹åäº†
MODEL_NAME = os.environ.get("LLM_MODEL_NAME", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B")

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
cr = Crossref()

def get_oa_link_from_doi(doi):
    """åˆ©ç”¨ Unpaywall API æŸ¥æ‰¾ DOI æ˜¯å¦æœ‰å…è´¹ PDF"""
    try:
        email = "bot@example.com"
        r = requests.get(f"https://api.unpaywall.org/v2/{doi}?email={email}", timeout=5)
        data = r.json()
        if data.get('is_oa') and data.get('best_oa_location'):
            return data['best_oa_location']['url_for_pdf']
    except:
        pass
    return None

def detect_and_extract_all(text):
    """æå–æ‰€æœ‰æ–‡çŒ®é“¾æ¥"""
    results = []
    seen_ids = set() 

    # 1. ArXiv
    for match in re.finditer(r"(?:arXiv ID:|arxiv\.org/abs/)\s*(\d+\.\d+)", text, re.IGNORECASE):
        aid = match.group(1)
        if aid not in seen_ids:
            results.append({"type": "arxiv", "id": aid, "url": f"https://arxiv.org/pdf/{aid}.pdf"})
            seen_ids.add(aid)

    # 2. DOI
    for match in re.finditer(r"doi:\s*(10\.\d{4,9}/[-._;()/:A-Z0-9]+)", text, re.IGNORECASE):
        doi = match.group(1)
        if doi not in seen_ids:
            oa_url = get_oa_link_from_doi(doi)
            results.append({"type": "doi", "id": doi, "url": oa_url})
            seen_ids.add(doi)

    # 3. PDF Links
    for match in re.finditer(r'(https?://[^\s]+\.pdf)', text, re.IGNORECASE):
        url = match.group(1)
        if any(x in url for x in seen_ids): continue
        url_hash = hashlib.md5(url.encode()).hexdigest()
        if url_hash not in seen_ids:
            results.append({"type": "direct_pdf", "id": None, "url": url})
            seen_ids.add(url_hash)

    return results

def fetch_content(source_data, save_dir=None):
    """ä¸‹è½½å¹¶æå–å†…å®¹"""
    content = ""
    saved_file_path = None

    # A. PDF ä¸‹è½½
    if source_data["url"] and source_data["url"].endswith(".pdf"):
        print(f"    ğŸ“¥ [ä¸‹è½½] {source_data['url']}")
        time.sleep(3) 
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            r = requests.get(source_data["url"], headers=headers, timeout=60)
            if r.status_code == 200:
                file_id = source_data.get('id') or hashlib.md5(source_data['url'].encode()).hexdigest()
                safe_name = re.sub(r'[\\/*?:"<>|]', '_', file_id)
                filename = f"temp_{safe_name}.pdf"
                if save_dir:
                    filename = os.path.join(save_dir, f"{safe_name}.pdf")

                with open(filename, "wb") as f:
                    f.write(r.content)
                
                content = pymupdf4llm.to_markdown(filename)
                
                if save_dir:
                    saved_file_path = filename
                else:
                    os.remove(filename)
                    
                return content, "PDF Full Text", saved_file_path
        except Exception as e:
            print(f"    âš ï¸ PDF ä¸‹è½½å¤±è´¥: {e}")

    # B. DOI æ‘˜è¦
    if source_data["type"] == "doi":
        print(f"    â„¹ï¸ [å…ƒæ•°æ®] æŠ“å–æ‘˜è¦ DOI: {source_data['id']}")
        try:
            work = cr.works(ids=source_data["id"])
            title = work['message'].get('title', [''])[0]
            abstract = work['message'].get('abstract', 'æ— æ‘˜è¦ä¿¡æ¯')
            abstract = re.sub(r'<[^>]+>', '', abstract)
            content = f"# {title}\n\n## Abstract\n{abstract}"
            return content, "Abstract Only", None
        except:
            pass
            
    return None, "Unknown", None

def analyze_with_llm(content, content_type, source_url=""):
    """LLM åˆ†æå‡½æ•°"""
    prompt = f"""
    è¯·ä½œä¸ºæˆ‘çš„å­¦æœ¯åŠ©æ‰‹ï¼ŒåŸºäºä»¥ä¸‹æä¾›çš„æ–‡çŒ®å†…å®¹æ‰§è¡Œä»»åŠ¡ã€‚
    ã€æ–‡çŒ®å†…å®¹æ¥æºã€‘ï¼š{content_type}
    ã€å·²çŸ¥é“¾æ¥ã€‘ï¼š{source_url}

    ### ğŸ¨ è§†è§‰å¢å¼ºæŒ‡ä»¤ (é‡è¦)ï¼š
    åœ¨åˆ†æè¿‡ç¨‹ä¸­ï¼Œå¦‚æœé‡åˆ°**å¤æ‚çš„æ¨¡å‹æ¶æ„ã€ç®—æ³•æµç¨‹ã€ç”Ÿç‰©æœºåˆ¶ã€å…³é”®æ•°æ®å›¾è¡¨**æˆ–**æŠ½è±¡æ¦‚å¿µ**ï¼Œä¸ºäº†å¸®åŠ©è¯»è€…ç†è§£ï¼Œè¯·åœ¨ç›¸å…³æ®µè½åæ’å…¥å›¾ç‰‡æœç´¢æ ‡ç­¾ã€‚
    - **æ ¼å¼**ï¼š`
` 
    - **è¦æ±‚**ï¼šX å¿…é¡»æ˜¯å…·ä½“ã€å‡†ç¡®çš„æœç´¢å…³é”®è¯ï¼ˆè‹±æ–‡ä¸ºä½³ï¼‰ã€‚
    - **ç¤ºä¾‹**ï¼š
      - è®²åˆ°æ¨¡å‹ç»“æ„æ—¶æ’å…¥ï¼š``
      - è®²åˆ°å®éªŒç»“æœæ—¶æ’å…¥ï¼š``
    - **åŸåˆ™**ï¼šåªåœ¨æœ‰æ•™è‚²/è§£é‡Šæ„ä¹‰æ—¶æ’å…¥ï¼Œä¸è¦ä¸ºäº†ç¾è§‚è€Œæ’å…¥ã€‚

    ### ğŸ“ ä»»åŠ¡æ­¥éª¤ï¼ˆè¯·è¾“å‡º Markdown æ ¼å¼ï¼‰ï¼š
    1. **ç¡®è®¤å¹¶å¤è¿°æ–‡çŒ®åŸºæœ¬ä¿¡æ¯**ï¼šä»æ–‡ä¸­æå–å¹¶è¡¥å…¨ï¼šæ ‡é¢˜ã€ä½œè€…ã€æœŸåˆŠ/ä¼šè®®ã€å¹´ä»½ã€å…³é”®è¯ã€‚
    2. **ç ”ç©¶é¢†åŸŸä¸å½±å“åŠ›æ¨æ–­**ã€‚
    3. **ç ”ç©¶ç°çŠ¶ä¸ç¼ºå£**ã€‚
    4. **å…³é”®æŠ€æœ¯ä¸åˆ›æ–°**ï¼š(åœ¨æ­¤å¤„è‹¥æ¶‰åŠæ¶æ„ï¼Œè¯·åŠ¡å¿…æ’å…¥  æ ‡ç­¾)
    5. **æ ¸å¿ƒç»“è®º**ã€‚
    6. **æœ¯è¯­è§£é‡Š**ï¼šè§£é‡Š2-3ä¸ªä¸“ä¸šæœ¯è¯­ (é…åˆå›¾ç‰‡æ ‡ç­¾è¾…åŠ©è§£é‡Š)ã€‚
    7. **ä¼˜åŠ¿ä¸è´¡çŒ®**ã€‚
    8. **å±€é™æ€§ä¸æœªæ¥æ–¹å‘**ã€‚
    9. **ç›¸å…³æ–‡çŒ®æ¨è**ï¼šæ¨è3-5ç¯‡ã€‚
    10. **å­¦æœ¯æœç´¢æ¨¡æ‹Ÿ**ï¼šç»™å‡º3ä¸ªé€šè¿‡ Google Scholar æˆ– ArXiv è¿›ä¸€æ­¥ç ”ç©¶çš„å»ºè®®å…³é”®è¯ç»„åˆï¼Œæ ¼å¼ä¸ºï¼š`- å…³é”®è¯: [è§£é‡Š]`ã€‚
    11. **DOIä¸é“¾æ¥**ï¼šæä¾›DOIæˆ–æ›¿ä»£é“¾æ¥ã€‚
    12. **é‡åŒ–åˆ†ææå–**ï¼ˆå¦‚é€‚ç”¨ï¼‰ï¼šData/Datasetã€å˜é‡ã€æ¨¡å‹ã€ç»Ÿè®¡æ–¹æ³•ã€ç»“æœã€‚

    ---
    {content[:50000]} 
    ---
    """
    try:
        # ğŸŸ¢ è¿™é‡Œçš„ MODEL_NAME è¯»å–è‡ªç¯å¢ƒå˜é‡ï¼Œå»ºè®®ä½¿ç”¨ R1 æˆ– V3
        completion = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        analysis = completion.choices[0].message.content
        
        # ğŸŸ¢ã€æ¸…æ´—é€»è¾‘ã€‘å»é™¤ LLM ä¹ æƒ¯æ€§æ·»åŠ çš„ Markdown ä»£ç å—æ ‡è®°
        analysis = analysis.replace("```markdown", "").replace("```", "").strip()
        
        return analysis
        
    except Exception as e:
        return f"LLM åˆ†æå‡ºé”™: {e}"
