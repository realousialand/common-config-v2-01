import os
import re
import requests
import pymupdf4llm
from openai import OpenAI
from habanero import Crossref
from bs4 import BeautifulSoup
import time

# --- æ ¸å¿ƒé…ç½®åŒº ---
API_KEY = os.environ.get("LLM_API_KEY")
BASE_URL = "https://api.siliconflow.cn/v1"

# è¿™é‡Œå¡«å…¥ä½ æŒ‡å®šçš„ç¡…åŸºæµåŠ¨æ¨¡å‹ID
MODEL_NAME = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
cr = Crossref()

def detect_and_extract(text):
    """æ™ºèƒ½åˆ†æ‹£ï¼šæå– ArXiv ID, DOI æˆ– PDF é“¾æ¥"""
    result = {"type": None, "id": None, "url": None}
    
    # 1. ArXiv ID
    arxiv_match = re.search(r"arXiv ID:\s*(\d+\.\d+)", text)
    if arxiv_match:
        result["type"] = "arxiv"
        result["id"] = arxiv_match.group(1)
        result["url"] = f"https://arxiv.org/pdf/{result['id']}.pdf"
        return result

    # 2. DOI (Stork/æ–‡çŒ®é¸Ÿ)
    doi_match = re.search(r"doi:\s*(10\.\d{4,9}/[-._;()/:A-Z0-9]+)", text, re.IGNORECASE)
    if doi_match:
        result["type"] = "doi"
        result["id"] = doi_match.group(1)
        # å°è¯•æ‰¾ OA é“¾æ¥ï¼Œå¦‚æœæ‰¾ä¸åˆ°åç»­é€»è¾‘ä¼šå¤„ç†
        result["url"] = get_oa_link_from_doi(result["id"])
        return result

    # 3. ç›´æ¥ PDF é“¾æ¥ (Scholar)
    pdf_link_match = re.search(r'(https?://[^\s]+\.pdf)', text)
    if pdf_link_match:
        result["type"] = "direct_pdf"
        result["url"] = pdf_link_match.group(1)
        return result
    
    # 4. æ™®é€šç½‘é¡µé“¾æ¥ (Project MUSE)
    url_match = re.search(r'(https?://[^\s]+)', text)
    if url_match:
        result["type"] = "webpage"
        result["url"] = url_match.group(1)
        return result

    return None

def get_oa_link_from_doi(doi):
    """åˆ©ç”¨ Unpaywall API æŸ¥æ‰¾ DOI æ˜¯å¦æœ‰å…è´¹ PDF"""
    try:
        email = "bot@example.com" # Unpaywall è¦æ±‚
        r = requests.get(f"https://api.unpaywall.org/v2/{doi}?email={email}", timeout=10)
        data = r.json()
        if data.get('is_oa') and data.get('best_oa_location'):
            return data['best_oa_location']['url_for_pdf']
    except:
        pass
    return None

def fetch_content(source_data):
    """æ ¹æ®é“¾æ¥ä¸‹è½½ PDF æˆ–æŠ“å–æ‘˜è¦"""
    content = ""
    source_type = "Full Text"

    # A. å°è¯•ä¸‹è½½ PDF
    if source_data["url"] and source_data["url"].endswith(".pdf"):
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ PDF: {source_data['url']}")
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            r = requests.get(source_data["url"], headers=headers, timeout=60)
            if r.status_code == 200:
                with open("temp.pdf", "wb") as f:
                    f.write(r.content)
                content = pymupdf4llm.to_markdown("temp.pdf")
                os.remove("temp.pdf")
                return content, "PDF Full Text"
        except Exception as e:
            print(f"âš ï¸ PDF ä¸‹è½½å¤±è´¥: {e}")

    # B. å¦‚æœæ˜¯ DOI ä¸”æ²¡ä¸‹è½½åˆ° PDF -> æŠ“å…ƒæ•°æ®
    if source_data["type"] == "doi":
        print("â„¹ï¸ æ— æ³•è·å– PDFï¼Œå°è¯•æŠ“å– Crossref æ‘˜è¦...")
        try:
            work = cr.works(ids=source_data["id"])
            title = work['message'].get('title', [''])[0]
            abstract = work['message'].get('abstract', 'æ— æ‘˜è¦ä¿¡æ¯')
            abstract = re.sub(r'<[^>]+>', '', abstract) # æ¸…ç† XML æ ‡ç­¾
            content = f"# {title}\n\n## Abstract\n{abstract}"
            return content, "Abstract Only"
        except:
            pass

    # C. æ™®é€šç½‘é¡µæŠ“å–
    if source_data["type"] == "webpage":
        print("ğŸŒ æ­£åœ¨æŠ“å–ç½‘é¡µæ–‡æœ¬...")
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            r = requests.get(source_data["url"], headers=headers, timeout=30)
            soup = BeautifulSoup(r.text, 'html.parser')
            # ç§»é™¤å¯¼èˆªæ ç­‰æ‚é¡¹
            for script in soup(["script", "style", "nav", "footer"]):
                script.decompose()
            content = soup.get_text()
            return content[:15000], "Webpage Content" # æˆªå–å‰1.5ä¸‡å­—
        except:
            pass
            
    return None, "Unknown"

def analyze_with_llm(content, content_type):
    """è°ƒç”¨ LLM è¿›è¡Œåˆ†æ"""
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶åŠ©ç†ã€‚è¯·åˆ†æä»¥ä¸‹æ–‡çŒ®å†…å®¹ï¼ˆç±»å‹ï¼š{content_type}ï¼‰ã€‚
    
    è¯·è¾“å‡ºä¸€ä»½ç»“æ„æ¸…æ™°çš„ Markdown æŠ¥å‘Šï¼š
    1. **æ ‡é¢˜ä¸é¢†åŸŸ**: (æ¨æµ‹æ–‡çŒ®æ‰€å±çš„å…·ä½“å­é¢†åŸŸ)
    2. **ä¸€å¥è¯æ ¸å¿ƒ**: (TL;DR)
    3. **æ·±åº¦è§£æ**:
       - **ç ”ç©¶èƒŒæ™¯/ç—›ç‚¹**: (è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ)
       - **æ–¹æ³•è®º/æ•°æ®**: (å¦‚æœæ˜¯å®è¯ç ”ç©¶ï¼Œè¯·åˆ—å‡ºæ•°æ®æ¥æºã€æ¨¡å‹ï¼›å¦‚æœæ˜¯ç†è®ºï¼Œè¯·åˆ—å‡ºæ ¸å¿ƒè®ºç‚¹)
       - **ä¸»è¦ç»“è®º**: (å…·ä½“çš„å‘ç°)
    4. **ç”¨æˆ·ç›¸å…³æ€§**: 
       - ç”¨æˆ·å…³æ³¨ï¼šç¤¾ä¼šç§‘å­¦ã€å› æœæ¨æ–­ã€ä¸­å›½æ”¿æ²»ã€å¸å›½å²ã€‚
       - è¯·åˆ¤æ–­æ­¤æ–‡å¯¹ç”¨æˆ·çš„ä»·å€¼ï¼ˆé«˜/ä¸­/ä½ï¼‰å¹¶ç®€è¿°ç†ç”±ã€‚

    å†…å®¹å¦‚ä¸‹ï¼š
    ---
    {content[:50000]} 
    ---
    """
    
    try:
        completion = client.chat.completions.create(
            model=MODEL_NAME, # <--- è¿™é‡Œå·²ç»ä¿®æ”¹ä¸ºä½ æŒ‡å®šçš„æ¨¡å‹å˜é‡
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"LLM åˆ†æå‡ºé”™: {e}"
