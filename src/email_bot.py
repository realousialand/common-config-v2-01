import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
import datetime
import os
import json
import hashlib
from universal_bot import detect_and_extract, fetch_content, analyze_with_llm

# é…ç½®
EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASS = os.environ.get("EMAIL_PASS")
IMAP_SERVER = "imap.gmail.com"
SMTP_SERVER = "smtp.gmail.com"
HISTORY_FILE = "data/history.json"

# ä½ å…³æ³¨çš„é‚®ä»¶å…³é”®è¯
TARGET_SUBJECTS = ["æ–‡çŒ®é¸Ÿ", "Google Scholar Alert", "ArXiv", "Project MUSE", "new research", "Stork"]

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

def save_history(history_list):
    os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history_list, f, indent=2, ensure_ascii=False)

def get_unique_id(source_data):
    if source_data.get("id"):
        return source_data["id"]
    elif source_data.get("url"):
        return hashlib.md5(source_data["url"].encode()).hexdigest()
    return None

def connect_imap():
    mail = imaplib.IMAP4_SSL(IMAP_SERVER)
    mail.login(EMAIL_USER, EMAIL_PASS)
    return mail

def get_emails_from_today():
    mail = connect_imap()
    mail.select("inbox")
    # æœç´¢è¿‡å» 24 å°æ—¶çš„é‚®ä»¶
    date_str = (datetime.date.today() - datetime.timedelta(days=1)).strftime("%d-%b-%Y")
    status, messages = mail.search(None, f'(SINCE "{date_str}")')
    
    email_ids = messages[0].split()
    target_emails = []
    
    print(f"ğŸ” æ‰«æåˆ° {len(email_ids)} å°è¿‘æœŸé‚®ä»¶...")
    
    for e_id in email_ids:
        try:
            _, msg_data = mail.fetch(e_id, "(RFC822)")
            for response_part in msg_data:
                if isinstance(response_part, tuple):
                    msg = email.message_from_bytes(response_part[1])
                    subject, encoding = decode_header(msg["Subject"])[0]
                    if isinstance(subject, bytes):
                        subject = subject.decode(encoding if encoding else "utf-8")
                    
                    if any(keyword.lower() in subject.lower() for keyword in TARGET_SUBJECTS):
                        print(f"  âœ… å‘½ä¸­: {subject}")
                        target_emails.append(msg)
        except Exception as e:
            print(f"  âš ï¸ è¯»å–é‚®ä»¶å‡ºé”™: {e}")
            continue
    
    return target_emails

def extract_body(msg):
    if msg.is_multipart():
        for part in msg.walk():
            ctype = part.get_content_type()
            if ctype == "text/plain" and "attachment" not in str(part.get("Content-Disposition")):
                return part.get_payload(decode=True).decode()
            elif ctype == "text/html": 
                # ç®€å•å…œåº•ï¼Œä¼˜å…ˆç”¨ text/plain
                html = part.get_payload(decode=True).decode()
                return html
    else:
        return msg.get_payload(decode=True).decode()
    return ""

def send_daily_report(report_content):
    msg = MIMEText(report_content, "markdown", "utf-8")
    msg["Subject"] = f"ğŸ¤– AI æ–‡çŒ®æ—¥æŠ¥ - {datetime.date.today()}"
    msg["From"] = EMAIL_USER
    msg["To"] = EMAIL_USER 

    with smtplib.SMTP_SSL(SMTP_SERVER, 465) as server:
        server.login(EMAIL_USER, EMAIL_PASS)
        server.sendmail(EMAIL_USER, EMAIL_USER, msg.as_string())
    print("ğŸ“§ é‚®ä»¶å·²å‘é€ï¼")

def main():
    processed_ids = load_history()
    emails = get_emails_from_today()
    
    if not emails:
        print("ä»Šå¤©æ²¡æœ‰ç›¸å…³é‚®ä»¶ã€‚")
        return

    daily_report = "# ğŸ“… ä»Šæ—¥æ–‡çŒ®æ·±åº¦åˆ†æ\n\n"
    new_count = 0
    
    for msg in emails:
        subject = decode_header(msg["Subject"])[0][0]
        if isinstance(subject, bytes): subject = subject.decode()
        
        body = extract_body(msg)
        source_data = detect_and_extract(body)
        
        if not source_data:
            continue
            
        unique_id = get_unique_id(source_data)
        if unique_id in processed_ids:
            print(f"â­ï¸ å·²å­˜åœ¨å†å²è®°å½•: {unique_id}")
            continue

        print(f"ğŸš€ åˆ†æä¸­: {subject}")
        content, ctype = fetch_content(source_data)
        
        if content:
            analysis = analyze_with_llm(content, ctype)
            daily_report += f"## ğŸ“‘ {subject}\n**æ¥æº**: {source_data['url']}\n\n{analysis}\n\n---\n\n"
            processed_ids.append(unique_id)
            new_count += 1
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {subject}")

    if new_count > 0:
        send_daily_report(daily_report)
        save_history(processed_ids)
        print(f"å®Œæˆï¼æ›´æ–°äº† {new_count} æ¡è®°å½•ã€‚")
    else:
        print("æ²¡æœ‰æ–°å†…å®¹éœ€è¦å‘é€ã€‚")

if __name__ == "__main__":
    main()
