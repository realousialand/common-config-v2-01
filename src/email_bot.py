import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
import datetime
import os
import json
import hashlib
import time
import shutil
import zipfile
import socket  # ğŸ‘ˆ å…³é”®åº“ï¼šç”¨äºè®¾ç½®ç½‘ç»œè¶…æ—¶
from universal_bot import detect_and_extract_all, fetch_content, analyze_with_llm

# --- æ ¸å¿ƒé…ç½®åŒº ---
# 1. è®¾ç½®å…¨å±€ç½‘ç»œè¶…æ—¶ (60ç§’)ï¼Œé˜²æ­¢ IMAP æˆ–ä¸‹è½½æ— é™å¡æ­»
socket.setdefaulttimeout(60)

EMAIL_USER = os.environ.get("EMAIL_USER")
EMAIL_PASS = os.environ.get("EMAIL_PASS")
IMAP_SERVER = "imap.gmail.com"
SMTP_SERVER = "smtp.gmail.com"
HISTORY_FILE = "data/history.json"
DOWNLOAD_DIR = "downloads" # ä¸´æ—¶å­˜æ”¾ä¸‹è½½æ–‡ä»¶çš„ç›®å½•

# 2. é‚®ä»¶é™„ä»¶å®‰å…¨é˜ˆå€¼ (19MB)
# Gmail é™åˆ¶ 25MBï¼Œé¢„ç•™ Base64 ç¼–ç è†¨èƒ€ç©ºé—´ï¼Œ19MB æ˜¯å®‰å…¨çº¿
MAX_ATTACHMENT_SIZE = 19 * 1024 * 1024 

# é‚®ä»¶ç™½åå•
TARGET_SUBJECTS = ["æ–‡çŒ®é¸Ÿ", "Google Scholar Alert", "ArXiv", "Project MUSE", "new research", "Stork"]

def load_history():
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

def save_history(history_list):
    os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history_list, f, indent=2, ensure_ascii=False)

def get_unique_id(source_data):
    if source_data.get("id"):
        return source_data["id"]
    elif source_data.get("url"):
        return hashlib.md5(source_data["url"].encode()).hexdigest()
    return None

# --- é‚®ä»¶é“¾æ¥éƒ¨åˆ† ---

def connect_imap():
    mail = imaplib.IMAP4_SSL(IMAP_SERVER)
    mail.login(EMAIL_USER, EMAIL_PASS)
    return mail

def get_emails_from_today():
    try:
        mail = connect_imap()
        mail.select("inbox")
        date_str = (datetime.date.today() - datetime.timedelta(days=1)).strftime("%d-%b-%Y")
        status, messages = mail.search(None, f'(SINCE "{date_str}")')
        
        email_ids = messages[0].split()
        target_emails = []
        
        print(f"ğŸ” æ‰«æåˆ° {len(email_ids)} å°è¿‘æœŸé‚®ä»¶...")
        
        for e_id in email_ids:
            try:
                _, msg_data = mail.fetch(e_id, "(RFC822)")
                for response_part in msg_data:
                    if isinstance(response_part, tuple):
                        msg = email.message_from_bytes(response_part[1])
                        subject, encoding = decode_header(msg["Subject"])[0]
                        if isinstance(subject, bytes):
                            subject = subject.decode(encoding if encoding else "utf-8")
                        
                        if any(keyword.lower() in subject.lower() for keyword in TARGET_SUBJECTS):
                            # éšç§ä¿æŠ¤ï¼šæ—¥å¿—ä¸­ä¸æ‰“å°å®Œæ•´æ ‡é¢˜
                            print(f"  âœ‰ï¸ [å‘½ä¸­é‚®ä»¶] *** æ ‡é¢˜å·²éšè— ***")
                            target_emails.append(msg)
            except Exception as e:
                print(f"  âš ï¸ è¯»å–æŸå°é‚®ä»¶å‡ºé”™: {e}")
                continue
        return target_emails
    except Exception as e:
        print(f"âŒ IMAP è¿æ¥æˆ–æœç´¢å¤±è´¥: {e}")
        return []

def extract_body(msg):
    if msg.is_multipart():
        for part in msg.walk():
            ctype = part.get_content_type()
            if ctype == "text/plain" and "attachment" not in str(part.get("Content-Disposition")):
                return part.get_payload(decode=True).decode()
            elif ctype == "text/html": 
                html = part.get_payload(decode=True).decode()
                return html
    else:
        return msg.get_payload(decode=True).decode()
    return ""

# --- é™„ä»¶æ‰“åŒ…ä¸åˆ†å‘é€»è¾‘ ---

def batch_files_by_size(file_paths, max_size):
    """
    æ™ºèƒ½åˆ†å †ç®—æ³•ï¼šå°†æ–‡ä»¶åˆ—è¡¨æ‹†åˆ†æˆå¤šä¸ªæ‰¹æ¬¡ï¼Œæ¯æ‰¹æ¬¡ä¸è¶…è¿‡ max_size
    """
    batches = []
    current_batch = []
    current_batch_size = 0
    
    for f_path in file_paths:
        if not os.path.exists(f_path): continue
        
        f_size = os.path.getsize(f_path)
        
        # å•ä¸ªæ–‡ä»¶è¿‡å¤§ï¼Œå¼ºåˆ¶å•ç‹¬ä¸€å°
        if f_size > max_size:
            print(f"  âš ï¸ æ–‡ä»¶è¿‡å¤§ ({f_size/1024/1024:.2f}MB)ï¼Œå°†å•ç‹¬åˆ†åŒ…: {os.path.basename(f_path)}")
            batches.append([f_path])
            continue
            
        if current_batch_size + f_size > max_size:
            batches.append(current_batch)
            current_batch = [f_path]
            current_batch_size = f_size
        else:
            current_batch.append(f_path)
            current_batch_size += f_size
            
    if current_batch:
        batches.append(current_batch)
        
    return batches

def create_zip_for_batch(batch_files, batch_index):
    """ä¸ºæ‰¹æ¬¡åˆ›å»º ZIP"""
    zip_name = f"papers_part_{batch_index}.zip"
    print(f"ğŸ“¦ æ­£åœ¨æ‰“åŒ…ç¬¬ {batch_index} æ‰¹é™„ä»¶ ({len(batch_files)} ä¸ªæ–‡ä»¶)...")
    
    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zf:
        for file in batch_files:
            zf.write(file, os.path.basename(file))
            
    return zip_name

def send_email_with_attachment(subject, body, attachment_zip=None):
    msg = MIMEMultipart()
    msg["Subject"] = subject
    msg["From"] = EMAIL_USER
    msg["To"] = EMAIL_USER 
    
    msg.attach(MIMEText(body, "markdown", "utf-8"))

    if attachment_zip and os.path.exists(attachment_zip):
        try:
            with open(attachment_zip, "rb") as f:
                part = MIMEApplication(f.read(), Name=os.path.basename(attachment_zip))
            part['Content-Disposition'] = f'attachment; filename="{os.path.basename(attachment_zip)}"'
            msg.attach(part)
        except Exception as e:
            print(f"âŒ é™„ä»¶æŒ‚è½½å¤±è´¥: {e}")

    try:
        with smtplib.SMTP_SSL(SMTP_SERVER, 465) as server:
            server.login(EMAIL_USER, EMAIL_PASS)
            server.sendmail(EMAIL_USER, EMAIL_USER, msg.as_string())
        print(f"ğŸ“§ é‚®ä»¶å·²å‘é€: {subject}")
        return True
    except Exception as e:
        print(f"âŒ å‘é€å¤±è´¥: {e}")
        return False

# --- ä¸»ç¨‹åº ---

def main():
    # åˆå§‹åŒ–ä¸‹è½½ç›®å½•
    if os.path.exists(DOWNLOAD_DIR):
        shutil.rmtree(DOWNLOAD_DIR)
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    
    processed_ids = load_history()
    emails = get_emails_from_today()
    
    if not emails:
        print("ä»Šå¤©æ²¡æœ‰ç›¸å…³é‚®ä»¶ã€‚")
        return

    daily_report_body = "# ğŸ“… ä»Šæ—¥æ–‡çŒ®æ·±åº¦åˆ†æ\n\n"
    total_new_count = 0
    all_downloaded_files = []
    
    for msg in emails:
        subject = decode_header(msg["Subject"])[0][0]
        if isinstance(subject, bytes): subject = subject.decode()
        
        body = extract_body(msg)
        source_list = detect_and_extract_all(body)
        
        if not source_list: continue
        print(f"    ğŸ” é‚®ä»¶å†…å‘ç° {len(source_list)} ç¯‡æ½œåœ¨æ–‡çŒ®...")
        
        for source_data in source_list:
            unique_id = get_unique_id(source_data)
            if unique_id in processed_ids:
                print(f"    â­ï¸ [è·³è¿‡] å·²åˆ†æè¿‡")
                continue

            print(f"    ğŸš€ [æ­£åœ¨åˆ†æ] ...")
            
            # --- å…³é”®è°ƒç”¨ï¼šåŒæ—¶è·å–å†…å®¹å’Œæ–‡ä»¶è·¯å¾„ ---
            # å¿…é¡»é…åˆæ›´æ–°åçš„ universal_bot.py ä½¿ç”¨
            content, ctype, saved_path = fetch_content(source_data, save_dir=DOWNLOAD_DIR)
            
            if saved_path:
                all_downloaded_files.append(saved_path)
            
            if content:
                analysis = analyze_with_llm(content, ctype, source_url=source_data.get('url', ''))
                paper_title = source_data.get('id', 'Paper')
                daily_report_body += f"## ğŸ“‘ {paper_title}\n\n{analysis}\n\n---\n\n"
                processed_ids.append(unique_id)
                total_new_count += 1
            else:
                print(f"    âŒ ä¸‹è½½/åˆ†æå¤±è´¥ï¼Œè·³è¿‡ã€‚")

    # --- ç»“æœå‘é€é€»è¾‘ ---
    if total_new_count > 0:
        base_subject = f"ğŸ¤– AI æ–‡çŒ®æ—¥æŠ¥ - {datetime.date.today()}"
        
        if not all_downloaded_files:
            # æ²¡æœ‰é™„ä»¶ï¼Œç›´æ¥å‘
            send_email_with_attachment(base_subject, daily_report_body, None)
        else:
            
            # æœ‰é™„ä»¶ï¼Œè¿›è¡Œåˆ†æ‰¹é€»è¾‘
            batches = batch_files_by_size(all_downloaded_files, MAX_ATTACHMENT_SIZE)
            total_batches = len(batches)
            
            print(f"ğŸ“¦ ä¸‹è½½æ–‡ä»¶æ€»æ•°: {len(all_downloaded_files)}ï¼Œæ‹†åˆ†ä¸º {total_batches} å°é‚®ä»¶å‘é€ã€‚")
            
            for i, batch in enumerate(batches):
                batch_num = i + 1
                zip_filename = create_zip_for_batch(batch, batch_num)
                
                subject_with_part = f"{base_subject} (é™„ä»¶ Part {batch_num}/{total_batches})"
                
                # ç¬¬ä¸€å°æ”¾æ­£æ–‡ï¼Œåé¢çš„åªæ”¾é™„ä»¶
                if batch_num == 1:
                    email_body = daily_report_body + f"\n\n> ğŸ“ **é™„ä»¶è¯´æ˜**ï¼šæ–‡çŒ®åŸæ–‡å·²æ‰“åŒ…ã€‚å…± {total_batches} å°é‚®ä»¶ï¼Œè¿™æ˜¯ç¬¬ {batch_num} å°ã€‚"
                else:
                    email_body = f"# ğŸ“ è¡¥å……é™„ä»¶ (Part {batch_num}/{total_batches})\n\nè¿™æ˜¯ä»Šæ—¥æ–‡çŒ®çš„åç»­åŸæ–‡åŒ…ï¼Œè¯·æŸ¥æ”¶ã€‚"
                
                send_email_with_attachment(subject_with_part, email_body, zip_filename)
                
                if os.path.exists(zip_filename):
                    os.remove(zip_filename)

        save_history(processed_ids)
        print(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±æ›´æ–° {total_new_count} ç¯‡æ–‡çŒ®ã€‚")
    else:
        print("â˜• æ‰€æœ‰å†…å®¹éƒ½å·²åˆ†æè¿‡ã€‚")

if __name__ == "__main__":
    main()
